\begin{titlepage}

%------------------------------Table des matieres------------------------------

\tableofcontents

%------------------------------Fin Table des matieres------------------------------
%------------------------------Resume du projet------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Résumé du projet}
\end{bf}
\end{center}

\vspace{1cm}

{
Dans le cadre de recherches sur les réseaux, tout particulièrement les réseaux sociaux, nous sommes rapidement amenés à traiter des quantités importantes de données. Les données provenant des réseaux peuvent être représentées sous forme de graphes, nous pouvons donc faire appel à certaines informations que la théorie des graphes nous permet d'obtenir. Par exemple, la taille d'un graphe en nombre de noeuds ou de liens. Ou encore utiliser des algorithmes permettant de parcourir les différents noeuds d'un graphe.
~\\ \\ 
Pour aller plus loin, la théorie des réseaux complexes permet de comprendre comment de tels réseaux se forment, grandissent, quelles caractéristiques ils partagent. Ceci permet par exemple de comprendre comment l'information ou une infection se propage dans un réseau.
~\\ \\
Afin d'obtenir de telles informations, il est nécessaire d'avoir à sa disposition un ensemble d'outils informatiques permettant d'y répondre de manière efficace, et ce dans un temps acceptable. Notre mission est donc d'analyser les solutions existantes de traitements de grands graphes, et de mettre au point une librairie répondant à cette problématique.
~\\\\
Le but est donc d'organiser les programmes existants en une librairie maintenable, évolutive et facilement
utilisable, sans oublier d'enrichir la librairie d'algorithmes classiques de la théorie des graphes, tout en portant un soin particulier à la performance.
}

%------------------------------Fin Resume du projet------------------------------
%------------------------------Introduction------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Introduction}
\end{bf}
\end{center}

\vspace{1cm}
{
Lors de la dernière décennie nous avons vu émerger de nombreux services de réseaux sociaux, c'est à dire des environnements collaboratifs centrés sur l'individu. En effet, il existe une multitude de réseaux sociaux, certains destinés à regrouper des amis de la vie réelle, comme Facebook. D'autres aident à trouver des relations professionnels (emplois, liens commerciaux), amicales, amoureuses, ou permettent la découverte et le partage de contenus.
\\ \\
L'ensemble de ces plateformes a vu son nombre d'utilisateurs exploser, comme c'est le cas pour Twitter (permettant le partage, la découverte, et le débat d'informations) qui est passé de 200 millions de comptes en Avril 2011 à 500 millions en Octobre 2012.
\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{tcot}
\caption{Diffusion du mème \#tcot sur les réseaux sociaux}
\end{figure}
\\ \\
L'analyse de ces données permet par exemple d'améliorer les résultats des moteurs de recherche, ou encore d'étudier les comportements sociaux. D'autre part, il est intéressant de connaître les comportements des utilisateurs les plus influents, dans le but de comprendre la raison de leur popularité, comprendre ce que leur apporte cette popularité et quels sont leurs buts (en politique par exemple).
\\ \\
Mais les réseaux ne sont pas limités aux réseaux sociaux, et peuvent faire leur apparition dans de multiples domaines : les transports, l'organisation hiérarchique d'une entreprise, les espaces géographiques, les connexions entres les neurones d'un cerveau, ou encore les interactions entre les protéines d'un composé chimique ou biologique. Tant de domaines qui cherchent pourtant des réponses communes.
\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{biology}
\caption{Interactions de protéines dans le Saccharomyces cerevisiae, une levure}
\end{figure}
\\ \\
Dans un premier temps, il est nécessaire de définir quelques concepts liés à la représentation de réseaux sous forme de graphes.
Un graphe est un ensemble de points, dont certaines paires sont directement reliées par un (ou plusieurs) lien(s). Ces liens peuvent être orientés, c'est-à-dire qu'un lien entre deux points u et v relie soit u vers v, soit v vers u : dans ce cas, le graphe est dit orienté. Sinon, les liens sont symétriques, et le graphe est dit non orienté. \\ Afin de représenter au mieux les données, nous pouvons placer des poids sur les noeuds ou sur les arêtes, par exemple : dans un graphe représentant des villes, on pourrait mettre une valeur en kilomètres sur les liens séparants 2 villes ; ou encore affecter le nombre d'habitants d'une ville à chaque noeud correspondant. Le degré d'un noeud correspond au nombre de ses voisins. On définit comme voisins d'un noeud N l'ensemble des noeuds ayant un lien direct avec N. 
\\ \\
Grâce à cela, il est déjà possible de répondre à certaines questions, comme par exemple trouver le chemin le plus court entre deux noeuds. Ou encore, de répondre à des problèmes comme le voyageur de commerce : on se place dans un graphe à n noeuds où l'on connaît les distances séparant chaque noeuds, trouver un chemin de longueur totale minimale qui passe exactement une fois par chaque noeuds et revienne au noeud de départ. L'ensemble des algorithmes de la théorie des graphes nous sert donc comme base pour nos algorithmes d'études de réseaux.
\\ \\ 
Dans un second temps, la théorie des réseaux complexes définit plusieurs mesures comme le nombre de sauts (utilisé dans les réseaux internet pour compter le nombre d'intermédiaire pour aller d'un point à un autre), ou encore la distribution des degrés, c'est à dire la probabilité qu'un noeud, choisi de manière aléatoire, comporte un certain degré. Le degré de séparation est également une notion importante qui définit le nombre de noeuds minimum pour aller d'un noeud à un autre.
\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{degreedistribution}
\caption{Exemple de la représentation de la distribution des degrés d'un graphe}
\end{figure}
\\ \\ 
Nous avons vu précédemment qu'avec la théorie des réseaux complexes, on recherche à comprendre comment les réseaux se forment, grandissent, et quelles caractéristiques ils partagent. Nous allons donc décrire plusieurs caractéristiques que les réseaux peuvent avoir en commun.
\\ \\ 
Un réseau est appelé small-world, en référence au phénomène du même nom qui indique que dans un graphe représentant un réseau social, il y a au plus $k$ (avec $k$ petit, souvent inférieur à $10$) degrés de séparation entre deux noeuds. L'idée est donc que, dans un réseau small-world, le degré de séparation entre deux noeuds est très petit (mathématiquement, il augmente de manière logarithmique en fonction de la taille du réseau).
\\ \\ 
Il existe également des réseaux appelés scale-free, dont la distribution des degrés suit une loi de puissance. Une loi de puissance est une relation entre deux quantités x et y qui peut s'écrire de la façon suivante :
$ y = ax^k $
De part la loi de puissance et son principe d'invariance d'échelle, les réseaux scale-free suivent cette propriété de loi de puissance peu importe l'échelle du graphe (nombre de noeuds/liens).
\\ \\ 
Nous pouvons être amenés à vouloir partitionner un ensemble d'utilisateurs, afin d'observer les groupes d'individus ayant une liaison forte (ces groupes sont appelés communautés~\cite{communautes, structure}). Grâce à ce que nous avons vu, nous pouvons par exemple essayer de savoir quels noeuds du réseau sont importants, influents, centraux, ou connaitre quel contenu recommander à quelqu'un dont on connaît les goûts de ses amis ou de sa communauté.
}

%------------------------------Fin Introduction------------------------------
%------------------------------Analyse de l'existant------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Analyse de l'existant}
\end{bf}
\end{center}

\vspace{1cm}
{
Actuellement, une partie des algorithmes que nous allons reprendre a déjà été implémentée, notre travail va donc consister à adapter ces algorithmes pour notre structure de données, et à implémenter nous-mêmes les algorithmes restants. 
Les al\=gorithmes que nous allons devoir traiter sont les suivants : \\ \\
	
\begin{description}
\item[Jaccard :] Il s'agit d'étudier le jaccard \cite{jaccard} de deux ensembles de sommets A et B, c'est à dire le cardinal de l'intersection de A et B, divisé par le cardinal de l'union de A et B. A est l'ensemble des voisins sortants et B l'ensemble des voisins entrants. \[J(A,B) = \frac{|A \cap B|}{|A \cup B|}\] Cela permet de voir les similitudes en deux ensembles. Par exemple, on peut comparer le voisinage de deux utilisateurs et déterminer leur ressemblance, ou encore comparer les communautés résultantes d'algorithmes différents, afin de voir leur correspondance. Il existe aussi OverlapIndex qui permet de mesurer le chevauchement de deux ensembles et est défini comme ceci : \[O(A,B) = \frac{|A \cap B|}{min(|A|,|B|)}\]
\item[K-core~\cite{alvarezhamelin} :] On cherche à obtenir un sous graphe maximal induit $G_{max}$, tel que chacun des degrés des nœuds de $G_{max}$ soit supérieur ou égal à K dans $G_{max}$. C'est la définition d'un sous graphe dense par l'assouplissement de la définition d'une clique (tous les sommets d'une clique sont deux-à-deux adjacents) car les cliques sont peu présentes dans les réseaux. On constate en général que dans des processus de diffusion d'informations, celle-ci se fait au sein d'un même core, du k le plus élevé vers le plus petit.
\newline
\item[Louvain :] Pour faire simple, on étudie avec cet algorithme la comparaison entre le fait que deux éléments  soient connectés, et leur probabilité de l'être. C'est grâce à cela qu'on peut détecter des communautés. On utilise donc la modularité pour que chaque nœud appartienne à une seule communauté. La modularité est définie par: \[\Delta=\sum_{i\,j}\left[ A_{i\,j}-\frac{d_i d_j}{2^m}\right] \delta\left(c_i , c_j \right)\] où $A_{i\,j}$ est la matrice d'adjacence, $\frac{d_i d_j}{2^m}$ est la probabilité de i et j d'être connectés et $\delta(c_i , c_j)$ le fait ou non que i et j soient dans la même communauté.

\newpage
\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{fast}
\caption{Un exemple des différentes étapes de l'algorithme de Louvain}
\end{figure}
\item[Guimera et Amaral :]  On se penchera ici sur le rôle que jouent les nœuds, c'est à dire s'ils sont hubs (s'ils sont incontournables dans une communauté), ce qui est définit par le z-score de leur degré interne - le nombre de nœuds de la m\^eme communauté auquel un nœud est connecté. Empiriquement, un hub est dit hub si ce score est supérieur à 2.5. On étudie également la connectivité d'un noeud aux autres communautés à travers la participation externe. Un noeud est dit connecteur s'il est connecté à beaucoup d'autres communautés. En revanche, il est dit périphérique s'il dispose de peu de connexions vers d'autres communautés que la sienne. Le z-score est défini comme suit: \[Z_i=\frac{l_i-\overline{L}}{\sigma_L}\] où $L = \{l_i,...,l_n\} $ avec $l$ les liaisons du nœud actuel, $L$ la moyenne des liaisons des nœuds de la communauté et $\sigma$ l'écart type. Le z-score du degré interne est la normalisation entre les différents graphes. Il permet d'obtenir le nombre de liaisons dans la communauté proportionnellement aux liaisons des autres nœuds de la communauté.\\ \[Z_i=\frac{d_{int}^i - \overline{d_{int}^{c_i}}}{\sigma_{d_{int}}^{c_i}}\] \\ \\ \\ \\La participation externe permet de connaître la connectivité avec l'extérieur (vers 0 quand peu connecté avec l'extérieur, vers 1 quand très connecté). \[P_i=\sum_i\left(\frac{d_c}{d_i}\right)^2\] $d_c$ est le degré du noeud i dans sa communauté.\cite{GA}
\newline
\item[Dugué et Perez  :] Ce dernier point est une adaptation des mesures de Guimera et Amaral. On traitera de la connectivité externe, en étudiant la diversité, l'intensité et l'hétérogénéité. La diversité correspond au z-score du nombre de communautés externes auquel le nœud est connecté. L'intensité correspond au z-score du nombre de liens vers l'extérieur. Enfin, l'hétérogénéité est l'écart type de la moyenne des liens vers les communautés extérieures, par communauté extérieure, et pour chaque nœud. \cite{NDAP1}\cite{NDAP2}  \\ 
\end{description} 
D'autre part, les algorithmes déjà codés sont répartis de manière éparse sur différents fichiers, et il n'y a aucune cohésion entre eux ; notre travail va donc être de rassembler toutes les fonctionnalités de manière organisée, d'en faire une librairie.
}

%------------------------------Fin Analyse de l'existant------------------------------
%------------------------------Besoins non fonctionnels------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Besoins non fonctionnels}
\end{bf}
\end{center}

\vspace{1cm}
{
Ce qui est attendu de nous pour ces travaux, c'est de débuter la constitution d'une librairie, comportant tous les algorithmes abordés précédemment, qui simplifierait leur utilisation de manière uniformisée et par conséquent simplifierait l'étude des grands graphes.
\\ \\ 
}

\subsection{Choix du langage}
{
\textbf{Description :} Notre bibliothèque devra être développée en C++.

\textbf{Priorité :} 10/10

\textbf{Justification :} Les solutions existantes sont déjà en C++. De plus, les programmes qui utilisent les solutions existantes le sont également. Enfin, cela permet un usage simple dans des programmes en C++. Par ailleurs, C++ est un language performant et OpenMP permet de paralléliser simplement du code C++ . Ainsi, par souci de continuité et de performance, C++ est choisi.
}

\subsection{Environnement cible}
\subsubsection{La machine Speed}
{
\textbf{Description :} L'environnement cible de notre bibliothèque est la machine Speed qui comporte 64 coeurs et 64 Go de RAM. En outre l'utilisation de la mémoire doit être limitée.

\textbf{Priorité :} 10/10

\textbf{Justification :} Avec 64Go et des réseaux qui peuvent en occuper la moitié, il est nécessaire d'avoir des algorithmes n'abusant pas de la mémoire vive.
}

\subsubsection{Algorithmes non-récursif}
{
\textbf{Description :} On tentera d'éviter au maximum l'utilisation d'algorithme récursif.

\textbf{Priorité :} 9/10

\textbf{Justification :} Les graphes peuvent comporter un très grand nombre de nœuds et de sommets (plusieurs millions de nœuds), il est donc important de ne pas utiliser d'algorithme récursif sur le nombre de nœuds par exemple. En effet, la pile d'appel de fonctions pourrait ne pas pouvoir contenir l'ensemble de nos appels récursif et ferait donc planter l'exécution de notre programme avec une erreur de type \textit{StackOverflow}.
}

\subsection{Performance}
\subsubsection{Utilisation de la mémoire vive}
{
\textbf{Description :} L'environnement cible comporte 64 Go de RAM, son utilisation est donc limitée. Néanmoins, il est nécessaire de savoir l'utiliser intelligemment.

\textbf{Priorité :} 10/10

\textbf{Justification :} En effet, bien qu'étant une ressource précieuse, la RAM peut nous aider à améliorer les performances en temps de nos algorithmes. En outre, si stocker certaines informations en mémoire (sans en abuser) lors de l'utilisation d'un algorithme permet d'augmenter sensiblement sa rapidité d'exécution, alors il est important d'étudier si le gain en temps vaut le sacrifice en mémoire.
}

\subsubsection{Temps de calcul}
{
\textbf{Description :} Les algorithmes ne doivent pas nécessiter une exécution de plus de quelques heures sur des réseaux tels que Twitter, sans compter la parallélisation.

\textbf{Priorité :} 10/10

\textbf{Justification :} Étant donné la quantité d'informations à traiter et le nombre de personnes utilisant la machine Speed, il est nécessaire de restreindre son temps d'utilisation.
}

\subsection{Mise en place d'une bibliothèque dynamique}
{
\textbf{Description :} Si possible, nous pourrions mettre en place une librairie dynamique sous forme de .DLL (Windows) et .so (Linux). \cite{dll1}\cite{dll2}\cite{dll3} Dans le cas contraire, la bibliothèque sera utilisée comme les solutions existantes, c'est à dire comme un ensemble de fichiers .h et .cpp (fichier template et code source de C++).

\textbf{Priorité :} 1/10

\textbf{Justification :} Une bibliothèque dynamique sert à regrouper l'ensemble d'une bibliothèque de fonctions sous un seul fichier (.dll ou .so), permettant une distribution facilitée de la bibliothèque à une tierce personne. De plus, cela permet d'avoir une seule instance de la bibliothèque qui s'exécute et répond aux demandes en temps réel.
}

%------------------------------Fin Besoins non fonctionnels------------------------------
%------------------------------Besoins fonctionnels------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Besoins fonctionnels}
\end{bf}
\end{center}

\subsection{Code}

\subsubsection{Pattern}
{
\textbf{Description :} Utilisation de design pattern.

\textbf{Priorité :} 10/10

\textbf{Justification :} La librairie sur laquelle nous travaillons doit pouvoir être enrichie par la suite, et ce facilement, sans avoir à se plonger dans le code. Le principe du design pattern est de penser la conception d'un programme, l'organisation des classes le composant, de manière à pouvoir intégrer très aisément de nouveaux composants, à travers une structure du code modulaire.
}

\subsubsection{Parallélisation}
{
\textbf{Description :} Afin d'améliorer le temps d'exécution de nos algorithmes, nous utiliserons OpenMP \cite{OpenMP}  sur les algorithmes les plus gourmands en temps.

\textbf{Priorité :} 9/10

\textbf{Justification :} En effet, l'environnement cible dispose de 64 coeurs, il est donc très intéressant de paralléliser nos programmes et de bénéficier d'un temps de calcul beaucoup plus réduit. OpenMP \cite{OpenMP} permet une parallélisation simple de programmes grâce à l'utilisation de directives (lignes de code qui seront remplacées à la compilation pour transformer certains blocs en blocs parallèles, avec des paramètres définis).
}

\subsection{Algorithmes}

\subsubsection{BFS}
{
\textbf{Description :} Breadth First Search, ou algorithme de parcours en largeur. \cite{BFS}

\textbf{Priorité :} 10/10

\textbf{Justification :} Cet algorithme permet le parcours d'un graphe de manière itérative, à l'aide d'une structure de type file. Nos algorithmes suivants requièrent pour la plupart à un moment ou à un autre de parcourir le graphe à étudier, cet algorithme est donc fondamental.
}

\subsubsection{Jaccard}
{
\textbf{Description :} Permet de connaître le jaccard \cite{jaccard} de deux ensembles.

\textbf{Priorité :} 9/10

\textbf{Justification :} Comme on l'a vu précédemment, le jaccard permet la comparaison de deux ensembles, cet algorithme est donc un élément essentiel puisqu'utilisé par plusieurs autres algorithmes.
}

\subsubsection{K-core}
{
\textbf{Description :} Obtention d'un sous graphe de type K-core

\textbf{Priorité :} 9/10

\textbf{Justification :} Il permet d'étudier la diffusion d'informations et les noyaux centraux qui les diffusent, et est lui aussi utilisé par d'autres algorithmes.
}

\subsubsection{Louvain}
{
\textbf{Description :} Comparaison entre le fait que deux objets soit connectés et leur probabilité de l'être.

\textbf{Priorité :} 8/10

\textbf{Justification :} Cet algorithme permet de détecter des communautés, son appartenance à la librairie est capitale, même si sa priorité n'est pas absolue du fait qu'il ne soit pas utilisé dans la plupart des autres algorithmes.
}

\subsubsection{Guimera et Amaral}
{
\textbf{Description :} Le rôle des nœuds.

\textbf{Priorité :} 7/10

\textbf{Justification :} Pour étudier un graphe, il est important de connaître l'importance de chaque nœud au sein de sa communauté comme au sein des autres communautés. Il est donc fort utile de disposer de cet algorithme dans notre librairie, mais, pour autant, peu d'algorithmes risquent d'avoir besoin de celui-ci.
}

\subsubsection{Dugué et Perez }
{
\textbf{Description :} Adaptation des mesures de Guimera et Amaral.

\textbf{Priorité :} 6/10

\textbf{Justification :} Cet algorithme servira pour traiter la connectivité externe, à travers la diversité, l'intensité et l'hétérogénéité. De même que Guimera et Amaral, cet algorithme sera beaucoup utilisé pour étudier les graphes, mais ne sera pas intégré à d'autres algorithmes.
}

\subsection{Tests}

{
\textbf{Description :} Réalisation de tests.

\textbf{Priorité :} 8/10

\textbf{Justification :} Lorsque l'on écrit un programme, il est nécéssaire de vérifier qu'il fonctionne ; pour cela on réalise des tests. Ces tests permettent de s'assurer que le code ne bug pas, qu'il réalise ce pourquoi il a été écrit, et qu'il ne fait rien d'autre que cela. Il est donc vital pour notre librairie de tester notre code.
}

\subsection{Documentation}

{
\textbf{Description :} Ajout de documentation au code.

\textbf{Priorité :} 10/10

\textbf{Justification :} De manière à rendre un code compréhensible par toutes les personnes ayant à le relire, que ce soit pour ceux qui l'écrivent au départ ou pour ceux qui le reprendront, il est important de bien le documenter : de la sorte sa compréhension sera facilitée.
}

\vspace{1cm}
\subsection{Prototype papier}

\begin{figure}[h]
\centering
\includegraphics[width=0.99\textwidth]{proto0}
\caption{Prototype papier de la bibliothèque}
\end{figure}

{
La librairie que nous allons constituer devra rassembler l'ensemble des algorithmes que nous serons à même de retranscrire depuis la solution existante, c'est à dire l'ensemble des algorithmes vus précédemment. Mais elle devra également comporter des algorithmes de base de la théorie des graphes, tels que le parcours en largeur ou celui en profondeur. \\ L'objectif est d'avoir une librairie suffisamment flexible et modulaire, afin que de nombreux algorithmes puissent être ajoutés et cela même après la fin de ce TER.
\\ \\ 
C'est pourquoi il est essentiel de mettre en place un modèle permettant de représenter un graphe, qu'il soit orienté ou non, de pouvoir convertir un graphe orienté en non-orienté. Ou encore, de pouvoir utiliser un graphe de la même manière qu'il soit orienté ou non, ce qui peut être utile dans des algorithmes qui ne se préoccupent pas de l'orientation. En outre, il est important de pouvoir spécifier si une fonction prend en paramètre uniquement un graphe orienté, non-orienté ou les deux.
\\ \\ 
Afin de faciliter l'utilisation de la librairie, nous avons effectué des recherches sur la mise en place d'une librairie dynamique. Ceci permet de pouvoir facilement partager le code présent dans la librairie pour de multiples exécutions, et ce sans avoir accès à l'implémentation de la librairie, facilitant ainsi la distribution de cette dernière auprès de tierces personnes. Pour autant, les difficultés liées aux environnements de développement multiples (Linux avec l'extension .so, et Windows avec l'extension .dll), nous amèneraient à passer du temps sur une fonctionnalité non-essentielle, temps qui pourrait être mieux investi.
\\ \\ 
C'est pour cette raison que la librairie sera constituée de multiples fichiers .cpp et .h, comme c'est le cas de la solution existante. En effet, cela permet une utilisation simple et rapide de l'ensemble de la librairie pour l'écriture d'un nouveau projet de manipulation de graphe, et ce, peu importe l'environnement de développement ou d'exécution. C'est également un moyen permettant plus de libertés quant à l'enrichissement de cette librairie.
\\ \\ 
L'utilisation de cette librairie s'effectuera par l'inclusion des bons fichier header (\#include "Graphe.h"), et l'utilisation des fonctions et classes sera aussi aisée que l'utilisation de classes et fonctions d'un projet en cours. Bien évidement, aucune interface graphique n'est demandée, puisque le but est de fournir un ensemble d'outils (classes et fonctions) permettant la mise en œuvre simple, rapide et uniforme de nouveaux projets/solutions pour le traitement des graphes importants, sur super-calculateurs.
}

%------------------------------Fin Besoins fonctionnels------------------------------
%------------------------------Prototypes et resultats de tests------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Prototypes et résultats de tests}
\end{bf}
\end{center}

\vspace{1cm}
{
Nous avons tout d'abord commencé par coder la structure de données permettant de gérer les grands graphes. Notre structure de données est constituée d'une classe Graphe permettant de gérer les graphes de manière globale, et nous avons ensuite deux classes GrapheOriente et GrapheNonOriente qui permettent, comme leur nom l'indique, de gérer la différence entre les graphes orientés et les graphes non orientés.
\begin{figure}[h]
\centering
\includegraphics[width=0.99\textwidth]{proto1}
\caption{Graphes orientés, graphes non orientés}
\end{figure}
~\\ \\
	Les deux classes de graphes sont composées de plusieurs tableaux qui permettent de stocker les arcs de chaque sommet ainsi que les degrés de ces même sommets. La principale différence entre les deux classes est que, pour un graphe orienté, les tableaux sont dédoublés afin d'avoir accès aux arcs et degrés sortants ou entrants. Le but de cette structure de données est d'avoir un accès à un élément i d'un tableau en temps constant. \\  \\ Nous avons donc choisi de coder les tableaux grâce à des vectors. Nous avons opté pour cette structure car elle permet un accès en temps O(1) à un élément n du tableau, et permet également d'avoir des tableaux dynamiques, et donc de rajouter facilement de nouveaux nœuds dans le graphe. Pour le moment, le stockage des poids est encore assez incertain, nous avons essayé de le stocker dans un vector, mais les résultats ne sont pas forcément convaincants.
~\\ \\
	Une fois la structure de données créée, nous avons écrit les fonctions de base, permettant de récupérer les données du graphe, tels que les voisins d'un sommet, ou son degré, de façon constante. Ce dernier point est très important, comme nous devons travailler sur de très grands graphes. La première fonction que nous avons codé est celle permettant de récupérer les degrés d'un sommet. Pour ce faire, nous avons le tableau des degrés cumulatifs. Ce tableau stocke par exemple à la case N le degré du sommet N ainsi que tous les degrés des sommets précédents, stockés dans le tableau. Donc le degré de la case N correspondra à la valeur en N, moins la valeur en N-1. Cela donne un accès en temps O(1), tout en conservant les valeurs précédentes, et donc en ayant le nombre total d'arcs stockés à la dernière case du tableau.
~\\ \\
	La deuxième fonction dont nous avions besoin est celle permettant de récupérer les arcs correspondant à un sommet N. Pour cela nous utilisons un deuxième tableau, qui est celui correspondant aux arcs. Afin de récupérer la liste des sommets voisins de N, nous avons besoin de connaître deux éléments. Le premier est le degré du sommet récupéré grâce à la méthode vue précédemment. Le deuxième est bien sûr la première case à regarder dans le tableau des arcs, que nous pouvons récupérer grâce à la case N-1 du tableau des degrés cumulatifs. En effet, cette case nous indique directement la case à regarder dans le tableau. Si elle est à 1, on se place à la case 1 du tableau des arcs. Il nous suffit ensuite de regarder le nombre de cases correspondant au degré du sommet N. Cela nous permet ainsi de récupérer les voisins en temps constant.
~\\ \\
	Nous pouvons voir dans ce schéma comment marche la liaison entre les deux tableaux, grâce à un exemple.
\begin{figure}[h]
\centering
\includegraphics[width=0.99\textwidth]{proto2}
\caption{Liaison entre nos deux tableaux}
\end{figure}
~\\ \\
	L'une des difficultés pour tester notre prototype est bien entendu la taille des graphes. Pour une question de mémoire vive ainsi que de temps d’exécution, nous n'avons pas testé notre prototype sur les graphes pour lesquels notre code sera dédiés. Malgré cela, le fait de travailler sur des graphes beaucoup plus abordables ne nous handicape en aucun sens. Au contraire, cela nous permet un debuggage plus rapide. Nous pouvons bien entendu tester nos temps d'exécution sur de petits graphes, et ainsi voir si certains algorithmes sont effectivement plus rapides que d'autres.
~\\ \\
	À partir de ce point, nous avons codé notre premier algorithme à proprement parler, le BFS, ou algorithme de parcours en largeur. Cet algorithme est très important car il sera utilisé dans l'algorithme de Louvain, qui est l'un des algorithmes les plus importants du projet. L'algorithme du BFS permet de parcourir le graphe en temps O(n+m), et donc d'avoir un parcours de graphe efficace. 
~\\ \\
	Comme dit précédemment, nous avons testé notre code sur de petits graphes ; voici un exemple d'exécution dans la sortie console ci-dessous.
\begin{figure}[h]
\centering
\includegraphics[width=0.99\textwidth]{capture}
\caption{Sortie console}
\end{figure}
\\ \\
}
%------------------------------Fin Prototypes et resultats de tests------------------------------
%------------------------------Planning et affectation des taches------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Planning et affectation des taches}
\end{bf}
\end{center}

\vspace{1cm}
{
Pour mener à bien ce travail, nous prenons contact avec Nicolas Dugué une fois par semaine, pour faire le point sur nos avancées et définir ou redéfinir des objectifs. Nous utilisons un dépôt svn pour gérer les fichiers, et l'outil Trello pour nous répartir les tâches.
\begin{figure}[h]
\centering
\includegraphics[width=0.99\textwidth]{trello}
\caption{Notre page d'organisation sur Trello}
\end{figure}
\\ \\
Nous avons cinq algorithmes principaux à implémenter, mais les cinq n'ont pas la même complexité ; nous essayons donc de chacun travailler sur l'un des algorithmes, tout en faisant régulièrement le point pour pouvoir venir en aide à l'un ou l'autre si une difficulté est rencontrée. Si cette difficulté nous dépasse, nous n'hésiterons pas à faire appel à Nicolas Dugué et/ou à Anthony Perez.
\\ \\
Notre objectif est d'avancer progressivement, de construire notre librairie brique par brique, dans l'optique de la mener le plus loin possible, le mieux possible.
}

%------------------------------Fin Planning et affectation des taches------------------------------
%------------------------------Exemple de fonctionnement du logiciel final------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Exemple de fonctionnement du logiciel final}
\end{bf}
\end{center}

\vspace{1cm}
{
bla bla
}

%------------------------------Fin Exemple de fonctionnement du logiciel final------------------------------
%------------------------------Architecture------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Architecture}
\end{bf}
\end{center}

\vspace{1cm}
{
Nous avons choisis de mettre en place une architecture simple, une définition de graphe modulable avec un objet pour chaque algorithme qui s'articule autour.
\\ \\
La définition de graphe est le coeur de la librairie, c'est pourquoi nous avons choisie de faire une classe abstraite graphe qui est hérité par deux classes : une pour un graphe orienté et une autre pour un graphe non-orienté. Ceci permet de pouvoir utiliser de manière simple un graphe en paramètre d'une fonction. En effet, je peu demander un pointeur de Graphe si ma fonction s'exécute de la même manière pour un graphe orienté ou non. Alors que si tel n'est pas le cas, je peux créé deux fonctions pour gérer les deux types de graphes différemment. Graphe est certes une classe abstraite, mais elle spécifie les fonctions minimales qu'un graphe doit implémenter, on peut donc utiliser un graphe orienté ou non orienté de la même façon.
\\ \\
Le reste des algorithmes vient donc se greffer de manière modulable sur cette base qu'est l'implémentation des graphes. Tout en ajoutant leurs lots de fonctionnalités qui peuvent donc êtres à nouveau utilisées pour de nouveaux algorithmes.
}



\newpage
{
\begin{figure}[!h]
\centering
\includegraphics[width=0.99\textwidth]{diagrammeDeClasse}
\caption{Diagramme de classe}
\end{figure}
}


%------------------------------Fin Architecture------------------------------
%------------------------------Commentaires techniques------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Commentaires techniques}
\end{bf}
\end{center}

\vspace{1cm}
{

\subsection{Breadth First Search, ou algorithme de parcours en largeur.}
\subsubsection{Description technique}
{
L'algorithme de parcours en largeur (ou BFS, pour Breadth First Search) permet le parcours d'un graphe de manière itérative, en utilisant une file. Il peut par exemple servir à déterminer la connexité d'un graphe.
}
\subsubsection{Commentaires techniques}
{
Nous avons implémenté cette algorithme dans la classe \textit{Graphe}, car c'est un algorithme basique de parcours d'un graphe et qui s'utilise peut importe l'orientation de ce dernier.
}
\subsubsection{Justifications techniques}
{
Notre implémentation prend en paramètre un numéro de sommet, afin de définir la source du parcours, ainsi qu'un paramètre optionnel qui est un tableau de sommets à ne pas prendre en compte. Ceci peut permettre d'indiquer au parcours de ne pas utiliser certains sommets. Nous avons également choisis de retourner un tableau de booléen pour chaque sommet du graphe, vrai si le sommet à été trouver lors de la recherche, faux sinon. Ce tableau permet par exemple de vérifier la connexité d'un graphe.
}

\subsection{Jaccard et OverlapIndex}
\subsubsection{Description technique}
{
Ces algorithmes permettent de connaître la similarité et la diversité de deux ensembles.
}
\subsubsection{Commentaires techniques}
{
Nous avons implémenté cette algorithme dans la classe \textit{IndiceEnsembliste} afin de les regrouper puisqu'ils utilise les mêmes données.
}
\subsubsection{Justifications techniques}
{
Notre implémentation effectue la plus grande majorité des calculs dans le constructeur, ce qui permet d'obtenir la valeur du jaccard ou de l'overlapIndex avec une simple opération.
}

\subsection{K-core}
\subsubsection{Description technique}
{
Cette algorithme permet d'obtenir un graphe de type K-core permettant de mettre en évidence la diffusion d'informations et les noyaux centraux qui les diffusent.
}
\subsubsection{Commentaires techniques}
{
Nous avons implémenté cette algorithme dans la classe \textit{Kcore} afin d'être utilisé par d'autres algorithmes.
}
\subsubsection{Justifications techniques}
{
ELEONORE TODO
}

\subsection{Louvain}
\subsubsection{Description technique}
{
Cette algorithme permet de détecter les communautés d'un graphe via la maximisation d'une mesure appelée la modularité.
}
\subsubsection{Commentaires techniques}
{
Nous avons implémenté cette algorithme dans la classe \textit{Communaute}. Son constructeur permet de préciser le nombre de passes à effectuer pour la détection de communauté, ainsi que la modularité minimum en dessous de laquelle l'algorithme s'arrête. On peu également renseigné un paramètre facultatif pour indiquer à l'algorithme de débuter avec une certaine répartition des communautés déjà évaluée.
\\ \\ 
Afin de lancer l'algorithme, il est nécessaire de lancer la fonction \textit{effectuerUneEtape()}, nous avons garder ce fonctionnement afin de permettre une migration facilité des anciens codes vers une adaptation utilisant notre librairie.
\\ \\ 
Par la suite les informations peuvent êtres obtenus via \textit{getCommunauteNoeud()} qui renvoye la partition sous forme d'un tableau pour chaque communauté, l'ensemble de ses noeuds, ou via \textit{getNoeudCommunaute} qui renvoie la partition sous forme d'un tableau pour chaque noeud, la communauté à laquelle il appartient. On peut également obtenir le graphe où chaque noeud représente une communauté via \textit{getGrapheCommunaute()}.
}
\subsubsection{Justifications techniques}
{
Nous avons décidé de stocker l'ensemble des informations pour accélérer le temps de calcul, et la restitution d'informations via les getters (\textit{getCommunauteNoeud} et \textit{getNoeudCommunaute}). \textit{m\_in} permet de stocker pour chaque communauté la somme des poids des arcs internes et \textit{m\_tot} pour chaque communauté la somme des poids des arcs entrants depuis une autre communauté. Ces variables sont utilisées et mise à jour par plusieurs fonctions et représente le coeur des informations permettant de détecter les communautés.
\\ \\ 
Nous avons également trois variables permettant de stocker des informations sur le voisinage d'un sommet, ces informations sont utiles lorsque l'on décide si l'on doit changer le sommet de communauté. Ces informations pourrait être stocker temporairement dans une structure ad hoc, mais cela nécessiterait de recalculer une partie des données alors que actuellement le minimum de calcul est effectué pour mettre à jour ces informations.
}

\subsection{Guimera et Amaral}
\subsubsection{Description technique}
{
Cette algorithme permet d'obtenir le rôle des noeuds par rapport au graphe, à leur communauté ou aux autres communautés, et ceci par l'intermédiaire de deux mesures appelée z-score (statistique qui permet de conclure à la signifiance ou non d'un écart dans un profil) et participation (la participation permet de connaître la connectivité avec l'extérieur (participation externe) ou l'intérieur (participation interne) d'une communauté, cette mesure s'étend de 0 (peu connecté) à 1 (très connecté)).
}
\subsubsection{Commentaires techniques}
{
Nous avons implémenté cette algorithme dans la classe \textit{GuimeraAmaral} toujours dans l'idée de limiter d'effectuer les mêmes calculs puisque de nombreuses fonctions utilisent les mêmes données. Nous avons fait le choix de laisser les fonctions de calculs du z-score et de la participation accessible en public, mais nous avons tout de même mis en place des fonctions simples qui permettent de donner des significations à ces deux mesures. Par exemple pour savoir l'importance de connectivité d'un noeud.
}
\subsubsection{Justifications techniques}
{
Nous avons mis en place une implémentation pour graphe orienté et non-orienté, nous avons fais le choix de limiter les calculs en évitant de calculer ou de stocker les valeurs pour les arcs sortants d'un graphe non-orienté. En effet, nous calculons et stockons déjà les données pour les arcs entrants or ces données sont identiques à celles des arcs sortants dans le cas d'un graphe non-orienté. Les fonctions associés retournent donc la même chose dans ce cas (sortants/entrants).
\\ \\
D'autre part, nous avons stocké l'ensemble des informations qui sont utilisées à maintes reprises par les autres fonctions :}
\begin{itemize}
    \item \textit{m\_graphe} : le graphe
    \item \textit{m\_noeudCommunaute} : pour chaque noeud, la communauté à laquelle il appartient
    \item \textit{m\_communauteNoeud} : pour chaque communauté, la liste des noeuds lui appartenant
    \item \textit{m\_degreEntrantCommunaute} : degré interne de chaque noeud pour sa communauté
    \item \textit{m\_degreMoyenEntrantCommunaute} : pour chaque communauté, son degré moyen interne
    \item \textit{m\_degreSortantCommunaute} : degré externe de chaque noeud pour sa communauté
    \item \textit{m\_degreMoyenSortantCommunaute} : pour chaque communauté, son degré moyen sortant
    \item \textit{m\_ecartTypeEntrantCommunaute} : pour chaque communauté, son écart type interne
    \item \textit{m\_ecartTypeSortantCommunaute} : pour chaque communauté, son écart type externe
\end{itemize}

\subsection{Dugué et Perez}
\subsubsection{Description technique}
{
Cette algorithme est une amélioration de l'algorithme de Guimera et Amaral, il permet d'obtenir plusieurs informations en lieu et place de la participation externe :
}
\begin{itemize}
    \item l'intensité externe : évalue le nombre de liens d'un noeud avec d'autre communautés (autre que la sienne), par rapport aux autres noeuds de sa communauté
    \item la diversité : évalue le nombre de communautés auquel un noeud est connecté (autre que la sienne), par rapport aux autres noeuds de sa communauté
    \item l'hétérogénéité : mesure la variation du nombre de liens d'un noeud, d'une communauté à une autre
\end{itemize}
\subsubsection{Commentaires techniques}
{
Nous avons implémenté cette algorithme dans la classe \textit{ParticipationExterne}, cette classe éffectue l'ensemble des calculs dans son constructeur et ne sert par la suite qu'à sotcker les differentes informations.
}
\subsubsection{Justifications techniques}
{
Nous avons mis en place une implémentation qui une fois les calculs terminés permet d'obtenir une structure de donnée qui permet d'accéder rapidement aux trois mesures que sont l'intensité, la diversité et l'hétérogénéité.}
}

%------------------------------Fin Commentaires techniques------------------------------
%------------------------------Analyse en complexité des algorithmes------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Analyse en complexité des algorithmes}
\end{bf}
\end{center}

\vspace{1cm}
{
• Graphe.cpp
\\  \\
> Graphe::breadthFirstSearch \\ 
O(n*m) : \\
n le nombre de sommets à étudier, \\
m le nombre de voisins correspondants ; \\
O(n log(n)) dans le pire des cas. \\ \\

• Communaute.cpp
\\  \\
> Communaute::Communaute  \\
O(n*m) : \\
n le nombre de sommets dans la communauté, \\
m le nombre de voisins dans la bordne max ; \\
O(n log(n)) dans le pire des cas. \\ 
 \\
> Communaute::effectuerUneEtape \\
O(d*n*m) : \\
d le nombre de déplacements, \\
n le nombre de sommets à déplacer, \\
m le nombre de voisins correspondants ; \\
O(n log(n)) dans le pire des cas. \\ 
 \\
> Communaute::getGrapheCommunaute \\
O(c*n*m) : \\
c le nombre de communautés, \\
n le nombre de sommets à étudier, \\
m le nombre de voisins correspondants ; \\ 
O(n log(n)) dans le pire des cas.  \\  \\

• GrapheNonOriente.cpp
 \\  \\
> GrapheNonOriente::GrapheNonOriente \\
O(n*(m1+m2)) : \\
n le nombre de sommets à étudier, \\
m1 le nombre d'arcs entrants, 
m2 le nombre d'arcs sortants ; \\
O(n log(n)) dans le pire des cas. \\ \\

• GrapheOriente.cpp
 \\ \\
> GrapheOriente::GrapheOriente \\
O(n*(m1+m2)) : \\
n le nombre de sommets à étudier, \\
m1 le nombre d'arcs entrants, \\
m2 le nombre d'arcs sortants ; \\
O(n log(n)) dans le pire des cas. \\ \\

• GuimeraAmaral.cpp
 \\  \\
> GuimeraAmaral::GuimeraAmaral \\
> GuimeraAmaral::varianceEntrante \\
> GuimeraAmaral::varianceSortante \\
> GuimeraAmaral::degreMoyenEntrantCommunaute \\
> GuimeraAmaral::degreMoyenSortantCommunaute \\
> GuimeraAmaral::degreEntrantCommunaute \\
> GuimeraAmaral::degreSortantCommunaute \\
O(n) : \\
n le nombre de sommets ; \\
O(n) dans le pire des cas. \\ \\

• IndiceEnsembliste.cpp
 \\  \\
> IndiceEnsembliste::IndiceEnsembliste \\
> IndiceEnsembliste::overlapIndex \\
O(n) : \\
n le nombre de sommets ; \\
O(n) dans le pire des cas. \\ \\

• ParticipationExterne.cpp
 \\  \\
> ParticipationExterne::participationExterne \\
O(n*m) : \\
n le nombre de sommets dans la communauté, \\
m le nombre de voisins correspondants ; \\
O(n log(n)) dans le pire des cas. \\ \\

}

%------------------------------Fin Analyse en complexité des algorithmes------------------------------
%------------------------------Résultats des tests de validation------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Résultats des tests de validation}
\end{bf}
\end{center}

\vspace{1cm}
{
bla bla
}

%------------------------------Fin Résultats des tests de validation------------------------------
%------------------------------Extensions possibles------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Extensions possibles}
\end{bf}
\end{center}

\vspace{1cm}
{
bla bla
}

%------------------------------Fin Extensions possibles------------------------------
%------------------------------Bibliographie------------------------------

\newpage
\begin{center}
\begin{bf}
\section{Bibliographie}
\end{bf}
\end{center}
\bibliographystyle{unsrt} 
\bibliography{Bibliographie/BiblioBDD}	
%------------------------------Fin Bibliographie------------------------------
\end{titlepage}
